{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19e3a170-2828-454d-a0bf-3f351828209c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded models for: ['ADRO.JK_UpDown', 'ADRO.JK_DailyReturn', 'ADRO.JK_Volatility', 'BBCA.JK_UpDown', 'BBCA.JK_DailyReturn', 'BBCA.JK_Volatility', 'TLKM.JK_UpDown', 'TLKM.JK_DailyReturn', 'TLKM.JK_Volatility']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  3 of 3 completed\n",
      "2024-11-25 07:40:45,048 - Processing ticker: ADRO.JK\n",
      "2024-11-25 07:40:45,051 - Predicting ADRO.JK_UpDown...\n",
      "2024-11-25 07:40:45,076 - Predicting ADRO.JK_DailyReturn...\n",
      "2024-11-25 07:40:45,090 - Predicting ADRO.JK_Volatility...\n",
      "2024-11-25 07:40:45,101 - Processing ticker: BBCA.JK\n",
      "2024-11-25 07:40:45,104 - Predicting BBCA.JK_UpDown...\n",
      "2024-11-25 07:40:45,117 - Predicting BBCA.JK_DailyReturn...\n",
      "2024-11-25 07:40:45,135 - Predicting BBCA.JK_Volatility...\n",
      "2024-11-25 07:40:45,146 - Processing ticker: TLKM.JK\n",
      "2024-11-25 07:40:45,150 - Predicting TLKM.JK_UpDown...\n",
      "2024-11-25 07:40:45,158 - Predicting TLKM.JK_DailyReturn...\n",
      "2024-11-25 07:40:45,218 - Predicting TLKM.JK_Volatility...\n",
      "2024-11-25 07:40:45,253 - Predictions saved to RandomForest_predictions.json'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import logging\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "# Ticker symbols\n",
    "TICKER_SYMBOLS = ['ADRO.JK', 'BBCA.JK', 'TLKM.JK']\n",
    "START_DATE = \"2020-01-01\"\n",
    "# START_DATE = (datetime.today() - timedelta(days=365)).strftime('%Y-%m-%d')\n",
    "# END_DATE = datetime.today().strftime('%Y-%m-%d')\n",
    "END_DATE = (datetime.today() + timedelta(days=30)).strftime('%Y-%m-%d')\n",
    "\n",
    "def download_data(tickers, start_date, end_date):\n",
    "    \"\"\"Download historical stock data for given tickers and dates.\"\"\"\n",
    "    try:\n",
    "        data = yf.download(tickers, start=start_date, end=end_date, group_by='ticker', interval='1d')\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error downloading data: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def preprocess_data(data, ticker):\n",
    "    \"\"\"Preprocess data for a specific ticker.\"\"\"\n",
    "    if isinstance(data.columns, pd.MultiIndex):\n",
    "        data.columns = ['_'.join(col).strip() for col in data.columns]\n",
    "    else:\n",
    "        data.columns = data.columns.map(str)\n",
    "\n",
    "    # Calculate moving averages, daily return, and volatility\n",
    "    data[f'{ticker}_MA1'] = data[f'{ticker}_Close'].rolling(window=1).mean()\n",
    "    data[f'{ticker}_MA30'] = data[f'{ticker}_Close'].rolling(window=30).mean()\n",
    "    data[f'{ticker}_Volatility'] = data[f'{ticker}_Close'].pct_change().rolling(window=30).std()\n",
    "\n",
    "    return data.dropna()\n",
    "\n",
    "\n",
    "def load_model(filename):\n",
    "    \"\"\"Load model from pickle file.\"\"\"\n",
    "    try:\n",
    "        with open(filename, 'rb') as file:\n",
    "            return pickle.load(file)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading model: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def make_prediction(data, model, features):\n",
    "    \"\"\"Make predictions using the loaded model.\"\"\"\n",
    "    try:\n",
    "        X = data[features]\n",
    "        predictions = model.predict(X)\n",
    "        return predictions\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error making predictions: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Load models and results\n",
    "    model_data = load_model('../models/RandomForest_stock_models.pkl')\n",
    "    if not model_data:\n",
    "        print(\"Failed to load model data. Exiting.\")\n",
    "        return\n",
    "\n",
    "    models = model_data['models']\n",
    "    results = model_data['scores']\n",
    "    print(f\"Loaded models for: {list(models.keys())}\")\n",
    "\n",
    "    # Download recent data\n",
    "    data = download_data(TICKER_SYMBOLS, START_DATE, END_DATE)\n",
    "    if data is None:\n",
    "        print(\"Data download failed. Exiting program.\")\n",
    "        return\n",
    "\n",
    "    predictions = {}\n",
    "    for ticker in TICKER_SYMBOLS:\n",
    "        logging.info(f\"Processing ticker: {ticker}\")\n",
    "        ticker_data = preprocess_data(data, ticker)\n",
    "        ticker_data.reset_index(inplace=True)  # Ensure 'Date' is a column\n",
    "\n",
    "        for target, model in models.items():\n",
    "            if ticker not in target:\n",
    "                continue  # Skip models not associated with this ticker\n",
    "\n",
    "            # Identify the feature set based on the target\n",
    "            feature_map = {\n",
    "                'UpDown': [f'{ticker}_Open', f'{ticker}_Close', f'{ticker}_MA1'],\n",
    "                'DailyReturn': [f'{ticker}_Open', f'{ticker}_Close', f'{ticker}_High', f'{ticker}_Low'],\n",
    "                'Volatility': [f'{ticker}_Open', f'{ticker}_Close', f'{ticker}_Volume', f'{ticker}_MA30']\n",
    "            }\n",
    "\n",
    "            target_suffix = target.replace(f'{ticker}_', '')\n",
    "            features = feature_map.get(target_suffix)\n",
    "\n",
    "            if features is None:\n",
    "                logging.warning(f\"No features mapped for {target}\")\n",
    "                continue\n",
    "\n",
    "            # Predict\n",
    "            logging.info(f\"Predicting {target}...\")\n",
    "            ticker_predictions = make_prediction(ticker_data, model, features)\n",
    "\n",
    "            if ticker_predictions is not None:\n",
    "                predictions[target] = pd.DataFrame({\n",
    "                    'Date': ticker_data['Date'].dt.strftime('%Y-%m-%d'),  # Format Date\n",
    "                    'Prediction': ticker_predictions\n",
    "                }).to_dict(orient='records')\n",
    "    \n",
    "    # Save predictions to JSON\n",
    "    try:\n",
    "        with open('../predictions/RandomForest_Predictions.json', 'w') as file:\n",
    "            json.dump(predictions, file, indent=4, default=str)  # Use default=str for Date serialization\n",
    "        logging.info(\"Predictions saved to RandomForest_predictions.json'\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error saving predictions: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
